#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SPD Phase 1-B: Analysis Engine
==================================
Auto-Fetch ê²°ê³¼ â†’ GPT-4o 4ëŒ€ ì˜ì—­ ì •ë°€ë¶„ì„ â†’ ChromaDB ìœ ì‚¬í”„ë¡œì íŠ¸ ë§¤ì¹­
â†’ Go/No-Go ìŠ¤ì½”ì–´ì¹´ë“œ â†’ ì¢…í•© ì§„ë‹¨ ë¦¬í¬íŠ¸ ìƒì„±

4ëŒ€ ë¶„ì„ ì˜ì—­:
  01. ì—­ëŸ‰ ë¶€í•©ë„ ë¶„ì„ (Capability Fit Score)
  02. ì‚¬ì „ ì¤€ë¹„ í•„ìš”ì‚¬í•­ (Pre-Bid Preparation)
  03. ì œì•ˆ ì„±ê³µìš”ì†Œ KSF (Key Success Factors)
  04. ì œì•ˆì„œ êµ¬ì„± ë°©í–¥ (Proposal Blueprint)

Usage:
  python spd_analysis_engine.py                              # ìµœì‹  fetch ê²°ê³¼ ë¶„ì„
  python spd_analysis_engine.py --fetch fetch_20260214.json  # íŠ¹ì • fetch ê²°ê³¼
  python spd_analysis_engine.py --bid 20260214001            # íŠ¹ì • ê³µê³ ë§Œ
  python spd_analysis_engine.py --dry-run                    # GPT ë¯¸í˜¸ì¶œ

Author: WKMG Automation (SPD System)
Version: 1.0.0
"""

import os
import sys
import json
import glob
import time
import argparse
import logging
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, List

# ---------------------------------------------------------------------------
# ì„œë“œíŒŒí‹°
# ---------------------------------------------------------------------------
try:
    from openai import OpenAI
except ImportError:
    print("âŒ openai í•„ìš”: pip install openai --break-system-packages")
    sys.exit(1)

try:
    import chromadb
except ImportError:
    chromadb = None
    print("âš ï¸ chromadb ë¯¸ì„¤ì¹˜ â€” ìœ ì‚¬ í”„ë¡œì íŠ¸ ë§¤ì¹­ ë¹„í™œì„±í™”")

# v2 ê³ ë„í™” í”„ë¡¬í”„íŠ¸ (ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ë‚´ì¥ v1 fallback)
try:
    from spd_prompts_v2 import SYSTEM_PROMPT_V2, build_analysis_prompt_v2
    PROMPT_VERSION = "v2"
except ImportError:
    PROMPT_VERSION = "v1"
    print("â„¹ï¸ spd_prompts_v2.py ë¯¸ë°œê²¬ â€” ë‚´ì¥ v1 í”„ë¡¬í”„íŠ¸ ì‚¬ìš©")

# ---------------------------------------------------------------------------
# ê²½ë¡œ & ì„¤ì •
# ---------------------------------------------------------------------------
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
CONFIG_PATH = os.path.join(SCRIPT_DIR, "config.json")

def load_config():
    defaults = {
        "openai_api_key": os.environ.get("OPENAI_API_KEY", ""),
        "openai_model": "gpt-4o",
        "chromadb_dir": os.path.join(SCRIPT_DIR, "chromadb"),
        "chromadb_collection": "wkmg_projects",
        "fetch_results_dir": os.path.join(SCRIPT_DIR, "data", "fetch_results"),
        "extracted_dir": os.path.join(SCRIPT_DIR, "data", "extracted"),
        "analysis_output_dir": os.path.join(SCRIPT_DIR, "data", "analysis_results"),
        "max_context_chars": 12000,
        "top_similar_projects": 5,
        "temperature": 0.3,
    }
    if os.path.exists(CONFIG_PATH):
        with open(CONFIG_PATH, "r", encoding="utf-8") as f:
            user_cfg = json.load(f)
        if "spd" in user_cfg:
            defaults.update(user_cfg["spd"])
        if "openai_api_key" in user_cfg:
            defaults["openai_api_key"] = user_cfg["openai_api_key"]
    if os.environ.get("OPENAI_API_KEY"):
        defaults["openai_api_key"] = os.environ["OPENAI_API_KEY"]
    if os.environ.get("RFP_OPENAI_API_KEY"):
        defaults["openai_api_key"] = os.environ["RFP_OPENAI_API_KEY"]
    return defaults

# ë¡œê¹…
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s", datefmt="%H:%M:%S")
log = logging.getLogger("AnalysisEngine")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# v1 ë‚´ì¥ í”„ë¡¬í”„íŠ¸ (v2 ë¯¸ë°œê²¬ ì‹œ í´ë°±)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SYSTEM_PROMPT_V1 = """ë‹¹ì‹ ì€ WKMG(WK Marketing Group)ì˜ B2G ì…ì°° ì „ëµ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

WKMG í”„ë¡œíŒŒì¼:
- 16ë…„ B2G ë§ˆì¼€íŒ… ì»¨ì„¤íŒ… ì „ë¬¸ê¸°ì—…
- 6ëŒ€ í•µì‹¬ ë„ë©”ì¸: ì‚¬íšŒì ê¸°ì—…, ë†ì‹í’ˆ, ì§€ì—­ë¸Œëœë“œ, ê³µê³µí™ë³´, ê´€ê´‘ë¬¸í™”, ì¤‘ì†Œê¸°ì—…ìœ í†µ
- B2B ëŒ€ê¸°ì—… ë¸Œëœë“œì „ëµ ì‹¤ì : LGì „ì, ë¡¯ë°, ì •ê´€ì¥, ì‚¼ì„± ë“± 17ê°œì‚¬
- ì‚¬íšŒì ê¸°ì—… ìœ í†µì§€ì› 7ë…„ ì—°ì† ìˆ˜ì£¼

ë¶„ì„ ì‹œ ì£¼ì˜ì‚¬í•­:
- êµ¬ì²´ì  ê·¼ê±° ì—†ì´ ë‚™ê´€ì  í‰ê°€ ê¸ˆì§€
- 70ì  ë¯¸ë§Œì€ ë°˜ë“œì‹œ NO-GO ë˜ëŠ” CONDITIONAL GO íŒë‹¨
- WKMGì˜ ì‹¤ì œ ì‹¤ì ê³¼ ì—°ê²°í•˜ì—¬ ë¶„ì„
- ê²½ìŸ í™˜ê²½ë„ ë°˜ë“œì‹œ ê³ ë ¤"""

def build_analysis_prompt_v1(bid_result: Dict, rfp_text: str, similar_projects: List[Dict]) -> str:
    """v1 ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    prompt_parts = []
    
    prompt_parts.append(f"""## ë¶„ì„ ëŒ€ìƒ ê³µê³ 
- ê³µê³ ëª…: {bid_result.get('title', '')}
- ë°œì£¼ê¸°ê´€: {bid_result.get('agency', '')}
- ì˜ˆì‚°: {bid_result.get('budget_str', '')}
- ê³µê³ ë²ˆí˜¸: {bid_result.get('bid_no', '')}
- ë“±ê¸‰: {bid_result.get('grade', '')}
""")
    
    if rfp_text:
        max_chars = 10000
        truncated = rfp_text[:max_chars]
        if len(rfp_text) > max_chars:
            truncated += f"\n\n... (ì›ë¬¸ {len(rfp_text):,}ì ì¤‘ {max_chars:,}ìë§Œ í‘œì‹œ)"
        prompt_parts.append(f"## RFP ì›ë¬¸ (ì²¨ë¶€íŒŒì¼ ì¶”ì¶œ)\n{truncated}")
    
    if similar_projects:
        prompt_parts.append("\n## WKMG ìœ ì‚¬ í”„ë¡œì íŠ¸ (ChromaDB ë§¤ì¹­)")
        for sp in similar_projects[:5]:
            prompt_parts.append(f"- {sp.get('filename', '?')} (ìœ ì‚¬ë„: {sp.get('similarity', 0):.0%}) â€” {sp.get('preview', '')[:100]}")
    
    prompt_parts.append("""
## ìš”ì²­: 4ëŒ€ ì˜ì—­ ì •ë°€ë¶„ì„ì„ JSONìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”.

```json
{
  "summary": "í•œì¤„ ìš”ì•½",
  "go_no_go": "GO | NO-GO | CONDITIONAL",
  "total_score": 75,
  "capability_fit": {
    "score": 80,
    "matching_domains": ["D1_ì‚¬íšŒì ê¸°ì—…"],
    "key_strengths": ["7ë…„ ì—°ì† ìˆ˜ì£¼ ì‹¤ì "],
    "gaps": ["í•´ë‹¹ ì—†ìŒ"],
    "evidence": "2018~2024 ì‚¬íšŒì ê¸°ì—… ìœ í†µì§€ì› 7íšŒ ìˆ˜í–‰"
  },
  "pre_bid_preparation": {
    "must_do": ["ë°œì£¼ê¸°ê´€ ì‚¬ì „ë¯¸íŒ… ì¶”ì§„"],
    "nice_to_have": ["íŒŒíŠ¸ë„ˆì‚¬ ì»¨ì†Œì‹œì—„ êµ¬ì„±"],
    "timeline_days": 14
  },
  "key_success_factors": {
    "top3_ksf": ["ì‹¤ì  ê¸°ë°˜ ì‹ ë¢°ì„±", "í˜„ì¥ ê²½í—˜", "ìœ í†µ ë„¤íŠ¸ì›Œí¬"],
    "differentiators": ["B2B+B2G ë³µí•© ì—­ëŸ‰"],
    "risks": ["ë‹´ë‹¹ì êµì²´ ê°€ëŠ¥ì„±"]
  },
  "proposal_blueprint": {
    "recommended_toc": ["ì‚¬ì—…ì´í•´", "ìˆ˜í–‰ì „ëµ", "ì‹¤ì ", "ì¡°ì§"],
    "page_estimate": "45~55p",
    "key_visuals": ["ì—°ë„ë³„ ì„±ê³¼ ì¶”ì´ ê·¸ë˜í”„"],
    "tone": "í˜„ì¥ ê²½í—˜ ê¸°ë°˜ ì‹¤ë¬´í˜•"
  },
  "competitive_landscape": {
    "likely_competitors": ["ê³µê³µì»¨ì„¤íŒ…ì‚¬"],
    "wkmg_advantage": "7ë…„ ì—°ì† ìˆ˜ì£¼ + ëŒ€ê¸°ì—… ë¸Œëœë“œ ì „ëµ",
    "win_probability": "75~85%"
  },
  "action_items": [
    {"action": "ë°œì£¼ê¸°ê´€ ë‹´ë‹¹ì ë¯¸íŒ…", "priority": "HIGH", "deadline": "ì…ì°° 2ì£¼ì „"}
  ]
}
```

ë°˜ë“œì‹œ ìœ íš¨í•œ JSONìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”.""")
    
    return "\n".join(prompt_parts)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ChromaDB ìœ ì‚¬ í”„ë¡œì íŠ¸ ë§¤ì¹­
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_similar_projects(query_text: str, config: Dict) -> List[Dict]:
    """ChromaDBì—ì„œ ìœ ì‚¬ ê³¼ê±° í”„ë¡œì íŠ¸ ë§¤ì¹­"""
    if not chromadb:
        return []
    
    db_dir = config.get("chromadb_dir", os.path.join(SCRIPT_DIR, "chromadb"))
    collection_name = config.get("chromadb_collection", "wkmg_projects")
    
    if not os.path.exists(db_dir):
        log.info("  â„¹ï¸ ChromaDB ì—†ìŒ â€” ìœ ì‚¬ í”„ë¡œì íŠ¸ ë§¤ì¹­ ìŠ¤í‚µ")
        return []
    
    try:
        client = chromadb.PersistentClient(path=db_dir)
        collection = client.get_collection(name=collection_name)
        
        # ì¿¼ë¦¬ í…ìŠ¤íŠ¸ ìš”ì•½ (ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ì„œ)
        query = query_text[:2000]
        n_results = config.get("top_similar_projects", 5)
        
        results = collection.query(query_texts=[query], n_results=n_results)
        
        matched = []
        if results and results.get("documents"):
            for i, doc in enumerate(results["documents"][0]):
                meta = results["metadatas"][0][i] if results.get("metadatas") else {}
                dist = results["distances"][0][i] if results.get("distances") else 999
                similarity = max(0, 1 - dist)
                
                matched.append({
                    "filename": meta.get("source_file", "unknown"),
                    "similarity": similarity,
                    "b2g_b2b": meta.get("b2g_b2b", ""),
                    "category": meta.get("category", ""),
                    "year": meta.get("year", ""),
                    "client": meta.get("client", ""),
                    "domain": meta.get("domain", ""),
                    "preview": doc[:200],
                })
        
        log.info(f"  ğŸ” ìœ ì‚¬ í”„ë¡œì íŠ¸ {len(matched)}ê±´ ë§¤ì¹­")
        return matched
        
    except Exception as e:
        log.warning(f"  âš ï¸ ChromaDB ë§¤ì¹­ ì‹¤íŒ¨: {e}")
        return []

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# GPT ë¶„ì„
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def call_gpt(system_prompt: str, user_prompt: str, config: Dict) -> Dict:
    """GPT-4o í˜¸ì¶œ ë° JSON íŒŒì‹±"""
    api_key = config.get("openai_api_key", "")
    if not api_key:
        return {"error": "OpenAI API í‚¤ ì—†ìŒ"}
    
    model = config.get("openai_model", "gpt-4o")
    temperature = config.get("temperature", 0.3)
    
    try:
        client = OpenAI(api_key=api_key)
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            temperature=temperature,
            max_tokens=4096,
            response_format={"type": "json_object"},
        )
        
        content = response.choices[0].message.content
        usage = response.usage
        
        log.info(f"  ğŸ’° í† í°: {usage.prompt_tokens:,} ì…ë ¥ + {usage.completion_tokens:,} ì¶œë ¥")
        
        result = json.loads(content)
        result["_meta"] = {
            "model": model,
            "prompt_tokens": usage.prompt_tokens,
            "completion_tokens": usage.completion_tokens,
            "total_tokens": usage.total_tokens,
        }
        return result
        
    except json.JSONDecodeError as e:
        log.error(f"  âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        return {"error": f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}", "raw": content if 'content' in dir() else ""}
    except Exception as e:
        log.error(f"  âŒ GPT í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return {"error": str(e)}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ë¶„ì„ íŒŒì´í”„ë¼ì¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def load_rfp_text(bid_result: Dict, config: Dict) -> str:
    """fetch ê²°ê³¼ì—ì„œ RFP í…ìŠ¤íŠ¸ ë¡œë“œ"""
    texts = []
    
    for extracted in bid_result.get("texts_extracted", []):
        text_file = extracted.get("text_file", "")
        if text_file and os.path.exists(text_file):
            try:
                with open(text_file, "r", encoding="utf-8") as f:
                    texts.append(f.read())
            except:
                pass
    
    combined = "\n\n---\n\n".join(texts)
    max_chars = config.get("max_context_chars", 12000)
    
    if len(combined) > max_chars:
        combined = combined[:max_chars] + f"\n\n... (ì›ë¬¸ {len(combined):,}ì ì¤‘ {max_chars:,}ìë§Œ í¬í•¨)"
    
    return combined

def analyze_bid(bid_result: Dict, config: Dict, dry_run: bool = False) -> Dict:
    """ë‹¨ì¼ ê³µê³  ë¶„ì„ ì‹¤í–‰"""
    bid_no = bid_result.get("bid_no", "unknown")
    title = bid_result.get("title", "")
    
    log.info(f"\n{'='*60}")
    log.info(f"ğŸ”¬ ë¶„ì„ ì‹œì‘: [{bid_result.get('grade','?')}] {title}")
    
    # Step 1: RFP í…ìŠ¤íŠ¸ ë¡œë“œ
    rfp_text = load_rfp_text(bid_result, config)
    log.info(f"  ğŸ“„ RFP í…ìŠ¤íŠ¸: {len(rfp_text):,}ì")
    
    # Step 2: ìœ ì‚¬ í”„ë¡œì íŠ¸ ë§¤ì¹­
    query_text = f"{title} {bid_result.get('agency', '')} {rfp_text[:1000]}"
    similar_projects = get_similar_projects(query_text, config)
    
    # Step 3: GPT ë¶„ì„
    if dry_run:
        log.info(f"  ğŸ” DRY-RUN â€” GPT í˜¸ì¶œ ìŠ¤í‚µ")
        return {
            "bid_no": bid_no,
            "title": title,
            "status": "dry_run",
            "rfp_text_length": len(rfp_text),
            "similar_projects": len(similar_projects),
        }
    
    log.info(f"  ğŸ¤– GPT-4o ì •ë°€ë¶„ì„ ì‹œì‘... (í”„ë¡¬í”„íŠ¸: {PROMPT_VERSION})")
    start_time = time.time()
    
    if PROMPT_VERSION == "v2":
        prompt = build_analysis_prompt_v2(bid_result, rfp_text, similar_projects)
        gpt_result = call_gpt(SYSTEM_PROMPT_V2, prompt, config)
    else:
        prompt = build_analysis_prompt_v1(bid_result, rfp_text, similar_projects)
        gpt_result = call_gpt(SYSTEM_PROMPT_V1, prompt, config)
    
    elapsed = time.time() - start_time
    log.info(f"  â±ï¸ ë¶„ì„ ì™„ë£Œ: {elapsed:.1f}ì´ˆ")
    
    # ê²°ê³¼ ì¡°í•©
    analysis = {
        "bid_no": bid_no,
        "title": title,
        "grade": bid_result.get("grade", "?"),
        "agency": bid_result.get("agency", ""),
        "budget_str": bid_result.get("budget_str", ""),
        "analyzed_at": datetime.now().isoformat(),
        "prompt_version": PROMPT_VERSION,
        "rfp_text_length": len(rfp_text),
        "similar_projects_count": len(similar_projects),
        "similar_projects": similar_projects,
        "analysis": gpt_result,
        "elapsed_seconds": round(elapsed, 1),
        "status": "error" if "error" in gpt_result else "completed",
    }
    
    # Go/No-Go ìš”ì•½
    go_decision = gpt_result.get("go_no_go", "UNKNOWN")
    total_score = gpt_result.get("total_score", 0)
    log.info(f"  ğŸ“Š ê²°ê³¼: {go_decision} ({total_score}ì )")
    
    return analysis

def find_latest_fetch(fetch_dir: str) -> Optional[str]:
    """ìµœì‹  fetch ê²°ê³¼ íŒŒì¼ ì°¾ê¸°"""
    patterns = [
        os.path.join(fetch_dir, "fetch_*.json"),
        os.path.join(fetch_dir, "*.json"),
    ]
    all_files = []
    for p in patterns:
        all_files.extend(glob.glob(p))
    if not all_files:
        return None
    return max(all_files, key=os.path.getmtime)

def run_analysis(args):
    """ë©”ì¸ ë¶„ì„ ì‹¤í–‰"""
    config = load_config()
    
    # fetch ê²°ê³¼ ë¡œë“œ
    if args.fetch:
        fetch_path = args.fetch
    else:
        fetch_dir = config.get("fetch_results_dir", os.path.join(SCRIPT_DIR, "data", "fetch_results"))
        fetch_path = find_latest_fetch(fetch_dir)
    
    if not fetch_path or not os.path.exists(fetch_path):
        log.error("âŒ Auto-Fetch ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        log.info("   ë¨¼ì € spd_auto_fetch.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    log.info(f"ğŸ“‚ Fetch ê²°ê³¼: {os.path.basename(fetch_path)}")
    
    with open(fetch_path, "r", encoding="utf-8") as f:
        fetch_data = json.load(f)
    
    results_list = fetch_data.get("results", [])
    log.info(f"   ê³µê³  ìˆ˜: {len(results_list)}ê±´")
    
    # í•„í„°ë§
    if args.bid:
        results_list = [r for r in results_list if args.bid in str(r.get("bid_no", ""))]
    
    # ë¶„ì„ ê°€ëŠ¥í•œ ê±´ë§Œ (í…ìŠ¤íŠ¸ ìˆê±°ë‚˜ ì œëª©ìœ¼ë¡œë¼ë„)
    analyzable = [r for r in results_list if r.get("status") in ("completed", "no_files", "dry_run")]
    if not analyzable:
        analyzable = results_list  # ì–´ì¨Œë“  ë¶„ì„ ì‹œë„
    
    log.info(f"   ë¶„ì„ ëŒ€ìƒ: {len(analyzable)}ê±´")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬
    output_dir = config.get("analysis_output_dir", os.path.join(SCRIPT_DIR, "data", "analysis_results"))
    os.makedirs(output_dir, exist_ok=True)
    
    # ë¶„ì„ ì‹¤í–‰
    analyses = []
    total_cost = 0
    
    for i, bid_result in enumerate(analyzable, 1):
        log.info(f"\n[{i}/{len(analyzable)}]")
        analysis = analyze_bid(bid_result, config, dry_run=args.dry_run)
        analyses.append(analysis)
        
        # ë¹„ìš© ì¶”ì 
        meta = analysis.get("analysis", {}).get("_meta", {})
        tokens = meta.get("total_tokens", 0)
        # GPT-4o: ~$5/1M input, ~$15/1M output (ëŒ€ëµ)
        cost_est = tokens * 0.00001
        total_cost += cost_est
        
        if i < len(analyzable):
            time.sleep(2)  # API ì¿¨ë‹¤ìš´
    
    # ê²°ê³¼ ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = os.path.join(output_dir, f"analysis_{timestamp}.json")
    
    output_data = {
        "generated_at": datetime.now().isoformat(),
        "fetch_source": fetch_path,
        "prompt_version": PROMPT_VERSION,
        "total_analyzed": len(analyses),
        "total_cost_estimate": f"${total_cost:.4f}",
        "analyses": analyses,
    }
    
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)
    
    # ìš”ì•½
    go_count = sum(1 for a in analyses if a.get("analysis", {}).get("go_no_go") == "GO")
    nogo_count = sum(1 for a in analyses if a.get("analysis", {}).get("go_no_go") == "NO-GO")
    cond_count = sum(1 for a in analyses if a.get("analysis", {}).get("go_no_go") == "CONDITIONAL")
    
    log.info(f"\n{'='*60}")
    log.info(f"âœ… SPD ë¶„ì„ ì™„ë£Œ")
    log.info(f"   GO: {go_count} | NO-GO: {nogo_count} | CONDITIONAL: {cond_count}")
    log.info(f"   ë¹„ìš©: ~${total_cost:.4f}")
    log.info(f"   ê²°ê³¼: {output_file}")
    log.info(f"{'='*60}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="SPD Analysis Engine")
    parser.add_argument("--fetch", help="íŠ¹ì • fetch ê²°ê³¼ JSON ê²½ë¡œ")
    parser.add_argument("--bid", help="íŠ¹ì • ê³µê³ ë²ˆí˜¸ë§Œ ë¶„ì„")
    parser.add_argument("--dry-run", action="store_true", help="GPT í˜¸ì¶œ ì—†ì´ êµ¬ì¡° í™•ì¸")
    
    args = parser.parse_args()
    run_analysis(args)
